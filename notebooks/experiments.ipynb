{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet(\"C:\\\\Users\\\\Cash Crusaders\\\\Desktop\\\\My Portfolio\\\\Projects\\\\Data Science Projects\\\\Data Science Project 11 - Laptop Price Prediction\\\\dataset\\\\feature_engineered_data\\\\X_train_df.parquet.gzip\")\n",
    "X_test = pd.read_parquet(\"C:\\\\Users\\\\Cash Crusaders\\\\Desktop\\\\My Portfolio\\\\Projects\\\\Data Science Projects\\\\Data Science Project 11 - Laptop Price Prediction\\\\dataset\\\\feature_engineered_data\\\\X_test_df.parquet\")\n",
    "y_train = pd.read_csv(\"C:\\\\Users\\\\Cash Crusaders\\\\Desktop\\\\My Portfolio\\\\Projects\\\\Data Science Projects\\\\Data Science Project 11 - Laptop Price Prediction\\\\dataset\\\\feature_engineered_data\\\\y_train_df.csv\")\n",
    "y_test = pd.read_csv(\"C:\\\\Users\\\\Cash Crusaders\\\\Desktop\\\\My Portfolio\\\\Projects\\\\Data Science Projects\\\\Data Science Project 11 - Laptop Price Prediction\\\\dataset\\\\feature_engineered_data\\\\y_test_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Company</th>\n",
       "      <th>TypeName</th>\n",
       "      <th>Cpu</th>\n",
       "      <th>Ram</th>\n",
       "      <th>Gpu</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Touchscreen</th>\n",
       "      <th>Ips</th>\n",
       "      <th>ppi</th>\n",
       "      <th>Cpu Name</th>\n",
       "      <th>Cpu brand</th>\n",
       "      <th>HDD</th>\n",
       "      <th>SSD</th>\n",
       "      <th>Gpu brand</th>\n",
       "      <th>os</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>1259</td>\n",
       "      <td>MSI</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>Intel Core i7 6700HQ 2.6GHz</td>\n",
       "      <td>8</td>\n",
       "      <td>Nvidia GeForce GTX 960M</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141.211998</td>\n",
       "      <td>Intel Core i7</td>\n",
       "      <td>Intel Core i7</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1007</td>\n",
       "      <td>HP</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>Intel Core i7 6600U 2.6GHz</td>\n",
       "      <td>8</td>\n",
       "      <td>Intel HD Graphics 520</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157.350512</td>\n",
       "      <td>Intel Core i7</td>\n",
       "      <td>Intel Core i7</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>Intel</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Company   TypeName                          Cpu  Ram  \\\n",
       "1259        1259     MSI     Gaming  Intel Core i7 6700HQ 2.6GHz    8   \n",
       "1007        1007      HP  Ultrabook   Intel Core i7 6600U 2.6GHz    8   \n",
       "\n",
       "                          Gpu  Weight  Touchscreen  Ips         ppi  \\\n",
       "1259  Nvidia GeForce GTX 960M    2.40            0    0  141.211998   \n",
       "1007    Intel HD Graphics 520    1.43            0    0  157.350512   \n",
       "\n",
       "           Cpu Name      Cpu brand   HDD  SSD Gpu brand       os  \n",
       "1259  Intel Core i7  Intel Core i7  1000  128    Nvidia  Windows  \n",
       "1007  Intel Core i7  Intel Core i7     0  256     Intel  Windows  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)\n",
    "# drop\n",
    "# Cpu\n",
    "# Gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1259</td>\n",
       "      <td>11.089517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1007</td>\n",
       "      <td>11.254190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     series\n",
       "0        1259  11.089517\n",
       "1        1007  11.254190"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "X_train.drop(columns=['Cpu'],inplace=True)\n",
    "X_train.drop(columns=['Gpu'],inplace=True)\n",
    "X_train.drop(columns=['Cpu Name'],inplace=True)\n",
    "y_train.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>TypeName</th>\n",
       "      <th>Ram</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Touchscreen</th>\n",
       "      <th>Ips</th>\n",
       "      <th>ppi</th>\n",
       "      <th>Cpu brand</th>\n",
       "      <th>HDD</th>\n",
       "      <th>SSD</th>\n",
       "      <th>Gpu brand</th>\n",
       "      <th>os</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>MSI</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>8</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141.211998</td>\n",
       "      <td>Intel Core i7</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>HP</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>8</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157.350512</td>\n",
       "      <td>Intel Core i7</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>Intel</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company   TypeName  Ram  Weight  Touchscreen  Ips         ppi  \\\n",
       "1259     MSI     Gaming    8    2.40            0    0  141.211998   \n",
       "1007      HP  Ultrabook    8    1.43            0    0  157.350512   \n",
       "\n",
       "          Cpu brand   HDD  SSD Gpu brand       os  \n",
       "1259  Intel Core i7  1000  128    Nvidia  Windows  \n",
       "1007  Intel Core i7     0  256     Intel  Windows  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.089517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.254190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series\n",
       "0  11.089517\n",
       "1  11.254190"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>10.776844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>10.881314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         series\n",
       "1039  10.776844\n",
       "1040  10.881314"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Company</th>\n",
       "      <th>TypeName</th>\n",
       "      <th>Cpu</th>\n",
       "      <th>Ram</th>\n",
       "      <th>Gpu</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Touchscreen</th>\n",
       "      <th>Ips</th>\n",
       "      <th>ppi</th>\n",
       "      <th>Cpu Name</th>\n",
       "      <th>Cpu brand</th>\n",
       "      <th>HDD</th>\n",
       "      <th>SSD</th>\n",
       "      <th>Gpu brand</th>\n",
       "      <th>os</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>1233</td>\n",
       "      <td>MSI</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>Intel Core i7 7700HQ 2.8GHz</td>\n",
       "      <td>16</td>\n",
       "      <td>Nvidia GeForce GTX 1060</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127.335675</td>\n",
       "      <td>Intel Core i7</td>\n",
       "      <td>Intel Core i7</td>\n",
       "      <td>1000</td>\n",
       "      <td>256</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>1030</td>\n",
       "      <td>HP</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>Intel Core i5 7200U 2.5GHz</td>\n",
       "      <td>4</td>\n",
       "      <td>Intel HD Graphics 620</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111.935204</td>\n",
       "      <td>Intel Core i5</td>\n",
       "      <td>Intel Core i5</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>Intel</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Company  TypeName                          Cpu  Ram  \\\n",
       "1233        1233     MSI    Gaming  Intel Core i7 7700HQ 2.8GHz   16   \n",
       "1030        1030      HP  Notebook   Intel Core i5 7200U 2.5GHz    4   \n",
       "\n",
       "                          Gpu  Weight  Touchscreen  Ips         ppi  \\\n",
       "1233  Nvidia GeForce GTX 1060    2.70            0    0  127.335675   \n",
       "1030    Intel HD Graphics 620    1.64            0    0  111.935204   \n",
       "\n",
       "           Cpu Name      Cpu brand   HDD  SSD Gpu brand       os  \n",
       "1233  Intel Core i7  Intel Core i7  1000  256    Nvidia  Windows  \n",
       "1030  Intel Core i5  Intel Core i5     0  256     Intel  Windows  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1233</td>\n",
       "      <td>11.352069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1030</td>\n",
       "      <td>10.855945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     series\n",
       "0        1233  11.352069\n",
       "1        1030  10.855945"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "X_test.drop(columns=['Cpu'],inplace=True)\n",
    "X_test.drop(columns=['Gpu'],inplace=True)\n",
    "X_test.drop(columns=['Cpu Name'],inplace=True)\n",
    "y_test.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "#set the tracking uri - needed for the ssqlite \n",
    "mlflow.set_tracking_uri(\"sqlite:///demo.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/1', creation_time=1680700375622, experiment_id='1', last_update_time=1680700375622, lifecycle_stage='active', name='demo-experiment-1', tags={}>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the experiment\n",
    "mlflow.set_experiment(\"demo-experiment-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score,mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor,ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.steps import step, Output, step_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input(X):\n",
    "    TypeName_map=X['TypeName'].value_counts().to_dict()\n",
    "    X['TypeName']=X['TypeName'].map(TypeName_map)\n",
    "    # company\n",
    "    company_map=X['Company'].value_counts().to_dict()\n",
    "    X['Company']=X['Company'].map(company_map)\n",
    "    #Cpu brand\n",
    "    cpu_brand_map=X['Cpu brand'].value_counts().to_dict()\n",
    "    X['Cpu brand']=X['Cpu brand'].map(cpu_brand_map)\n",
    "    # Gpu brand\n",
    "    gpu_brand_map=X['Gpu brand'].value_counts().to_dict()\n",
    "    X['Gpu brand']=X['Gpu brand'].map(gpu_brand_map)\n",
    "    # os\n",
    "    os_map=X['os'].value_counts().to_dict()\n",
    "    X['os']=X['os'].map(os_map)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train:pd.DataFrame, y_train:pd.DataFrame, X_val:pd.DataFrame, y_val:pd.DataFrame)->Output(\n",
    "    TRAINING_EXPERIMENT_NAME = str\n",
    "):\n",
    "    \n",
    "    mlflow.sklearn.autolog()\n",
    "    # X_train_transformed = convert_input(X_train)\n",
    "    # X_val_transformed = convert_input(X_val)\n",
    "    for model_class in (RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor,\n",
    "                        ExtraTreesRegressor,SVR,XGBRegressor,DecisionTreeRegressor,KNeighborsRegressor,\n",
    "                        LinearRegression,Ridge,Lasso):\n",
    "        \n",
    "        with mlflow.start_run(nested=True):\n",
    "            #tags of the runs\n",
    "            mlflow.set_tag(\"ml-engineer\", \"thobela\")\n",
    "            # column transformer iss used to transform columns,we are hot encoding 5 columns(the ones that have categorical values) usingg thei indexes\n",
    "            \n",
    "            column_transformer = ColumnTransformer(transformers=[\n",
    "                ('col_tnf',OneHotEncoder(sparse=False,drop='first'),[0,1,7,10,11])\n",
    "            ],remainder='passthrough')\n",
    "            X_train_tranformed = np.array(column_transformer.fit_transform(X_train))\n",
    "            X_val_tranformed = np.array(column_transformer.transform(X_val))\n",
    "            # Use a pipeline to enclose everything to make it easier for deployment\n",
    "            mlmodel = model_class()\n",
    "\n",
    "            # create a pipeline\n",
    "            # ml_pipeline = Pipeline([\n",
    "            #     ('step1',column_transformer),\n",
    "            #     ('step2',mlmodel)\n",
    "            # ])\n",
    "            mlmodel.fit(X_train_tranformed, y_train)\n",
    "\n",
    "            y_pred = mlmodel.predict(X_val_tranformed)\n",
    "            rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "            r2 = r2_score(y_val,y_pred)\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "            mlflow.log_metric(\"r2_score\", r2)\n",
    "            print(\"R2 Score : \",r2)\n",
    "            print(\"validation-rmse: \",rmse)\n",
    "            mlflow.end_run()\n",
    "    print(\"\\n\")\n",
    "    print('Sucessfully trained...')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>TypeName</th>\n",
       "      <th>Ram</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Touchscreen</th>\n",
       "      <th>Ips</th>\n",
       "      <th>ppi</th>\n",
       "      <th>Cpu brand</th>\n",
       "      <th>HDD</th>\n",
       "      <th>SSD</th>\n",
       "      <th>Gpu brand</th>\n",
       "      <th>os</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>MSI</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141.211998</td>\n",
       "      <td>Intel Core i7</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company TypeName  Ram  Weight  Touchscreen  Ips         ppi  \\\n",
       "1259     MSI   Gaming    8     2.4            0    0  141.211998   \n",
       "\n",
       "          Cpu brand   HDD  SSD Gpu brand       os  \n",
       "1259  Intel Core i7  1000  128    Nvidia  Windows  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>TypeName</th>\n",
       "      <th>Ram</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Touchscreen</th>\n",
       "      <th>Ips</th>\n",
       "      <th>ppi</th>\n",
       "      <th>Cpu brand</th>\n",
       "      <th>HDD</th>\n",
       "      <th>SSD</th>\n",
       "      <th>Gpu brand</th>\n",
       "      <th>os</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>MSI</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>16</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127.335675</td>\n",
       "      <td>Intel Core i7</td>\n",
       "      <td>1000</td>\n",
       "      <td>256</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company TypeName  Ram  Weight  Touchscreen  Ips         ppi  \\\n",
       "1233     MSI   Gaming   16     2.7            0    0  127.335675   \n",
       "\n",
       "          Cpu brand   HDD  SSD Gpu brand       os  \n",
       "1233  Intel Core i7  1000  256    Nvidia  Windows  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = column_transformer = ColumnTransformer(transformers=[\n",
    "                ('col_tnf',OneHotEncoder(sparse=False,drop='first'),[0,1,7,10,11])\n",
    "            ],remainder='passthrough')\n",
    "X_train_tranformed = np.array(ct.fit_transform(X_train))\n",
    "X_test_tranformed = np.array(ct.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261, 38)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tranformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1041, 38)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tranformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/07 15:56:22 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Anaconda\\envs\\machine-learning-env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:533: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score :  0.8806550096276546\n",
      "validation-rmse:  0.207282714727161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\machine-learning-env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score :  0.8615984902409635\n",
      "validation-rmse:  0.22321912674711508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\machine-learning-env\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score :  0.7999465243428561\n",
      "validation-rmse:  0.26837004654143415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/07 15:56:58 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Anaconda\\envs\\machine-learning-env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:533: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score :  0.8647216105805524\n",
      "validation-rmse:  0.22068621340837452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\machine-learning-env\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score :  0.5292633017939731\n",
      "validation-rmse:  0.4116707582950574\n",
      "R2 Score :  0.8696061806583709\n",
      "validation-rmse:  0.2166653656680409\n",
      "R2 Score :  0.8000474793733572\n",
      "validation-rmse:  0.26830232283630756\n",
      "R2 Score :  0.7042926066025396\n",
      "validation-rmse:  0.3262812237517812\n",
      "R2 Score :  0.7958532530922593\n",
      "validation-rmse:  0.2711016887308244\n",
      "R2 Score :  0.795377785078817\n",
      "validation-rmse:  0.2714172098372369\n",
      "R2 Score :  0.4501505300394437\n",
      "validation-rmse:  0.444920991470731\n",
      "\n",
      "\n",
      "Sucessfully trained...\n"
     ]
    }
   ],
   "source": [
    "train_model(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "from zenml.steps import step, Output, step_output\n",
    "from zenml.client import Client\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/2', creation_time=1680706923403, experiment_id='2', last_update_time=1680706923403, lifecycle_stage='active', name='hyper-optimization-experiment-1', tags={}>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MLFLOW_TRACKING_URI = get_tracking_uri()\n",
    "MLFLOW_TRACKING_URI = \"sqlite:///demo.db\"\n",
    "# assign a name for this hyperparameter tuning experiment\n",
    "TRAINING_EXPERIMENT_NAME = \"demo-experiment-1\"\n",
    "EXPERIMENT_NAME = \"hyper-optimization-experiment-1\"\n",
    "# set the stack experiment tracking uri to be the current working one\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "# set the current experiment name to be the current hyperparameter tuning one\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_param_datatypes(param_dict):\n",
    "    correct_param_dict={}\n",
    "    for k, v in param_dict.items():\n",
    "        if v != 'None' and v != 'True' and v != 'False' and v != 'squared_error' and k != 'criterion':\n",
    "            correct_param_dict[k] = float(v)\n",
    "        else:\n",
    "            correct_param_dict[k] = str(v)\n",
    "    return correct_param_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a function for optimizing the chosen number of models from the model runs\n",
    "def optimize_model(X_train:pd.DataFrame, y_train:pd.Series, X_val:pd.DataFrame, y_val:pd.Series, params, tags):\n",
    "   ''' X_train, X_test,y_train, y_test : for training and testing the models with new parameters\n",
    "    params: chosen paramters from a specific run\n",
    "   '''\n",
    "   estimator_name = tags['estimator_name']\n",
    "   pool_of_models = {\n",
    "      \"RandomForestRegressor\":RandomForestRegressor,\n",
    "      \"GradientBoostingRegressor\":GradientBoostingRegressor,\n",
    "      \"AdaBoostRegressor\":AdaBoostRegressor,\n",
    "      \"ExtraTreesRegressor\":ExtraTreesRegressor,\n",
    "      \"SVR\":SVR,\n",
    "      \"XGBRegressor\":XGBRegressor,\n",
    "      \"DecisionTreeRegressor\":DecisionTreeRegressor,\n",
    "      \"KNeighborsRegressor\":KNeighborsRegressor,\n",
    "      \"LinearRegression\":LinearRegression,\n",
    "      \"Ridge\":Ridge,\n",
    "      \"Lasso\":Lasso\n",
    "   }\n",
    "   model_class = pool_of_models[estimator_name]\n",
    "   param_dict = fix_param_datatypes(params)\n",
    "   # have a pool of values that will take on the different parameters, a seach space for values for the model\n",
    "   # assign as value pool space for different parameters where the models will take different parameters from\n",
    "        \n",
    "   with mlflow.start_run():\n",
    "\n",
    "      # start the logging of the experiment\n",
    "      mlflow.sklearn.autolog()\n",
    "      # column transformer iss used to transform columns,we are hot encoding 5 columns(the ones that have categorical values) usingg thei indexes\n",
    "      column_transformer = ColumnTransformer(transformers=[\n",
    "            ('col_tnf',OneHotEncoder(sparse=False,drop='first'),[0,1,7,10,11])\n",
    "      ],remainder='passthrough')\n",
    "      X_train_tranformed = np.array(column_transformer.fit_transform(X_train))\n",
    "      X_val_tranformed = np.array(column_transformer.transform(X_val))\n",
    "      # Use a pipeline to enclose everything to make it easier for deployment\n",
    "      # use the run paramters given to compoye the best paramters from the space pool\n",
    "      #params = space_eval(global_pool_space, params)\n",
    "      # assign those parameters to the model API class\n",
    "      mlmodel = model_class()\n",
    "\n",
    "      # fit the model with new parameters\n",
    "      mlmodel.fit(X_train_tranformed, y_train)\n",
    "      # do predictions with new parameters\n",
    "      y_pred = mlmodel.predict(X_val_tranformed)\n",
    "      # get the rsme and log it\n",
    "      rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "      r2 = r2_score(y_val,y_pred)\n",
    "      mlflow.log_metric(\"r2_score\", r2)\n",
    "      mlflow.log_metric(\"rmse\", rmse)\n",
    "      # mlflow.log_artifact(\"artifact/preprocessor.b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/1', creation_time=1680700375622, experiment_id='1', last_update_time=1680700375622, lifecycle_stage='active', name='demo-experiment-1', tags={}>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow_client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "mlflow_client.get_experiment(experiment_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/1', creation_time=1680700375622, experiment_id='1', last_update_time=1680700375622, lifecycle_stage='active', name='demo-experiment-1', tags={}>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = mlflow_client.get_experiment_by_name(TRAINING_EXPERIMENT_NAME)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow_client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.rmse ASC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': '0.9',\n",
       " 'ccp_alpha': '0.0',\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': 'None',\n",
       " 'learning_rate': '0.1',\n",
       " 'loss': 'squared_error',\n",
       " 'max_depth': '3',\n",
       " 'max_features': 'None',\n",
       " 'max_leaf_nodes': 'None',\n",
       " 'min_impurity_decrease': '0.0',\n",
       " 'min_samples_leaf': '1',\n",
       " 'min_samples_split': '2',\n",
       " 'min_weight_fraction_leaf': '0.0',\n",
       " 'n_estimators': '100',\n",
       " 'n_iter_no_change': 'None',\n",
       " 'random_state': 'None',\n",
       " 'subsample': '1.0',\n",
       " 'tol': '0.0001',\n",
       " 'validation_fraction': '0.1',\n",
       " 'verbose': '0',\n",
       " 'warm_start': 'False'}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs[4].data.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator model : sklearn.ensemble._forest.RandomForestRegressor, estimator_name : RandomForestRegressor, paramters:1.0\n",
      "estimator model : sklearn.ensemble._forest.RandomForestRegressor, estimator_name : RandomForestRegressor, paramters:1.0\n",
      "estimator model : sklearn.ensemble._forest.RandomForestRegressor, estimator_name : RandomForestRegressor, paramters:1.0\n",
      "estimator model : sklearn.ensemble._forest.ExtraTreesRegressor, estimator_name : ExtraTreesRegressor, paramters:1.0\n",
      "estimator model : sklearn.ensemble._gb.GradientBoostingRegressor, estimator_name : GradientBoostingRegressor, paramters:None\n"
     ]
    }
   ],
   "source": [
    "list_params = []\n",
    "for run in runs:\n",
    "    print(f\"estimator model : {run.data.tags['estimator_class']}, estimator_name : {run.data.tags['estimator_name']}, paramters:{run.data.params['max_features']}\")\n",
    "    params = fix_param_datatypes(run.data.params)\n",
    "    list_params.append(params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.9,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': 'None',\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'squared_error',\n",
       " 'max_depth': 3.0,\n",
       " 'max_features': 'None',\n",
       " 'max_leaf_nodes': 'None',\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1.0,\n",
       " 'min_samples_split': 2.0,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100.0,\n",
       " 'n_iter_no_change': 'None',\n",
       " 'random_state': 'None',\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0.0,\n",
       " 'warm_start': 'False'}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_params[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['True', '0.0', 'squared_error', 'None', '1.0', 'None', 'None', '0.0', '1', '2', '0.0', '100', 'None', 'False', 'None', '0', 'False'])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = list_params[0]\n",
    "param_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap : True\n",
      "ccp_alpha : 0.0\n",
      "criterion : squared_error\n",
      "max_depth : None\n",
      "max_features : 1.0\n",
      "max_leaf_nodes : None\n",
      "max_samples : None\n",
      "min_impurity_decrease : 0.0\n",
      "min_samples_leaf : 1\n",
      "min_samples_split : 2\n",
      "min_weight_fraction_leaf : 0.0\n",
      "n_estimators : 100\n",
      "n_jobs : None\n",
      "oob_score : False\n",
      "random_state : None\n",
      "verbose : 0\n",
      "warm_start : False\n"
     ]
    }
   ],
   "source": [
    "param_dict = list_params[0]\n",
    "param_dict.values()\n",
    "correct_param_dict={}\n",
    "for k, v in param_dict.items():\n",
    "    print(f\"{k} : {v}\")\n",
    "    if v != 'None' and v != 'True' and v != 'False' and v != 'squared_error':\n",
    "        correct_param_dict[k] = float(v)\n",
    "    else:\n",
    "        correct_param_dict[k] = str(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(correct_param_dict['warm_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model._coordinate_descent.Lasso"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_of_models = {\n",
    "       \"RandomForestRegressor\":RandomForestRegressor,\n",
    "       \"GradientBoostingRegressor\":GradientBoostingRegressor,\n",
    "       \"AdaBoostRegressor\":AdaBoostRegressor,\n",
    "       \"ExtraTreesRegressor\":ExtraTreesRegressor,\n",
    "       \"SVR\":SVR,\n",
    "       \"XGBRegressor\":XGBRegressor,\n",
    "       \"DecisionTreeRegressor\":DecisionTreeRegressor,\n",
    "       \"KNeighborsRegressor\":KNeighborsRegressor,\n",
    "       \"LinearRegression\":LinearRegression,\n",
    "       \"Ridge\":Ridge,\n",
    "       \"Lasso\":Lasso\n",
    "   }\n",
    "pool_of_models[\"Lasso\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForestRegressor': sklearn.ensemble._forest.RandomForestRegressor,\n",
       " 'GradientBoostingRegressor': sklearn.ensemble._gb.GradientBoostingRegressor,\n",
       " 'AdaBoostRegressor': sklearn.ensemble._weight_boosting.AdaBoostRegressor,\n",
       " 'ExtraTreesRegressor': sklearn.ensemble._forest.ExtraTreesRegressor,\n",
       " 'SVR': sklearn.svm._classes.SVR,\n",
       " 'XGBRegressor': xgboost.sklearn.XGBRegressor,\n",
       " 'DecisionTreeRegressor': sklearn.tree._classes.DecisionTreeRegressor,\n",
       " 'KNeighborsRegressor': sklearn.neighbors._regression.KNeighborsRegressor,\n",
       " 'LinearRegression': sklearn.linear_model._base.LinearRegression,\n",
       " 'Ridge': sklearn.linear_model._ridge.Ridge,\n",
       " 'Lasso': sklearn.linear_model._coordinate_descent.Lasso}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hey={}\n",
    "hey= pool_of_models\n",
    "hey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/2', creation_time=1680706923403, experiment_id='2', last_update_time=1680706923403, lifecycle_stage='active', name='hyper-optimization-experiment-1', tags={}>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_experiment = mlflow_client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "current_experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(TRAINING_EXPERIMENT_NAME: str, X_train:pd.DataFrame, y_train:pd.Series, X_val:pd.DataFrame, y_val:pd.Series)->Output(\n",
    "    model_name=str\n",
    "):\n",
    "    '''TRAINING_EXPERIMENT_NAME: the previous experiment for training\n",
    "    log_top_models: number of the top runs to get\n",
    "     X_train, X_test,y_train, y_test : for training and testing the models with new parameters\n",
    "    '''\n",
    "    \n",
    "    # get the  mlflow client that will enable us to communicate with the backend tracking uri to get the previous runs\n",
    "    mlflow_client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "    # get the experimeent of training  by name\n",
    "    experiment = mlflow_client.get_experiment_by_name(TRAINING_EXPERIMENT_NAME)\n",
    "    # get teh runs of the previous experiment\n",
    "    runs = mlflow_client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=5,\n",
    "        order_by=[\"metrics.rmse ASC\"]\n",
    "    )\n",
    "    # from the best top 5 or 10 runs , we get the parameters for that run and pass it to the optimze functon\n",
    "    for run in runs:\n",
    "        optimize_model(X_train,y_train,X_val,y_val,run.data.params,run.data.tags)\n",
    "\n",
    "    # select the model with the lowest test RMSE\n",
    "    # get the best performing model from the optimzed models, here we first get the name of the current hyperparamter tuning experiment\n",
    "    current_experiment = mlflow_client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    # get the best runs since they hav been optimized or tuned, from the list get the top run\n",
    "    # best_run = mlflow_client.search_runs(\n",
    "    #     experiment_ids=\"2\",\n",
    "    #     run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    #     max_results=1,\n",
    "    #     order_by=[\"metrics.rmse ASC\"]\n",
    "    # )[3]\n",
    "    # model_name=\"laptop-predicition-modelV1\"\n",
    "    # # register the best model(top of the list model)\n",
    "    # best_run_info = f\"best_run_info : {best_run.info}\"\n",
    "    # # mlflow.register_model(\n",
    "    # #     model_uri=model_uri, \n",
    "    # #     name=model_name\n",
    "    # # )\n",
    "    # return model_name, best_run_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign as value pool space for different parameters where the models will take different parameters from\n",
    "SPACE = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
    "    'n_estimators': scope.int(hp.normal('n_estimators', 10, 50, 1)),\n",
    "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\n",
    "    'random_state': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/07 18:58:12 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Anaconda\\envs\\machine-learning-env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:533: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\"\n",
      "2023/04/07 19:00:06 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Anaconda\\envs\\machine-learning-env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:533: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\"\n",
      "2023/04/07 19:00:42 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Anaconda\\envs\\machine-learning-env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:533: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\"\n",
      "2023/04/07 19:02:20 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Anaconda\\envs\\machine-learning-env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:533: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\"\n",
      "2023/04/07 19:04:27 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\CASHCR~1\\AppData\\Local\\Temp\\tmpnsj5uxcn\\model\\model.pkl, flavor: sklearn), fall back to return ['scikit-learn==1.1.2', 'cloudpickle==2.2.0']. Set logging level to DEBUG to see the full traceback.\n",
      "c:\\Anaconda\\envs\\machine-learning-env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "fine_tune_model(TRAINING_EXPERIMENT_NAME,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model registry MLFlow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interacting with Tracking Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"sqlite:///demo.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/2', creation_time=1680706923403, experiment_id='2', last_update_time=1680706923403, lifecycle_stage='active', name='hyper-optimization-experiment-1', tags={}>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interacting with the mlflow beckend tracker\\ tracking server\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "\n",
    "client.get_experiment(experiment_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import ViewType\n",
    "\n",
    "runs = client.search_runs(\n",
    "    experiment_ids='2',\n",
    "    filter_string=\"metrics.rmse < 7\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=2,\n",
    "    order_by=[\"metrics.rmse ASC\"]\n",
    ")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c10ad4177dad4049b3076f01582d130e'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 128731dce22e4a06bed20def94cf81db, rmse: 0.2046\n",
      "run id: c10ad4177dad4049b3076f01582d130e, rmse: 0.2061\n",
      "run id: 987e3045903948a7851fe036a4b672be, rmse: 0.2075\n",
      "run id: 3f179af39a0d4edb955d567a37826322, rmse: 0.2076\n",
      "run id: cdeb83a5a7874fa28e332ed2c2ac4f84, rmse: 0.2077\n"
     ]
    }
   ],
   "source": [
    "list_of_runs = []\n",
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}, rmse: {run.data.metrics['rmse']:.4f}\")\n",
    "    list_of_runs.append(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c10ad4177dad4049b3076f01582d130e'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_run = list_of_runs[0]\n",
    "best_run = runs.info.run_id\n",
    "best_run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interacting with Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'laptop-price-demoV2'.\n",
      "2023/04/10 13:02:41 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: laptop-price-demoV2, version 1\n",
      "Created version '1' of model 'laptop-price-demoV2'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1681124561823, current_stage='None', description=None, last_updated_timestamp=1681124561823, name='laptop-price-demoV2', run_id='c10ad4177dad4049b3076f01582d130e', run_link=None, source='./mlruns/2/c10ad4177dad4049b3076f01582d130e/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run_id = \"b8904012c84343b5bf8ee72aa8f0f402\"\n",
    "model_uri = f\"runs:/{best_run}/model\"\n",
    "mlflow.register_model(model_uri=model_uri, name=\"laptop-price-demoV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 1, stage: None\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "model_name = \"laptop-price-demoV2\"\n",
    "latest_versions = client.get_latest_versions(name=model_name)\n",
    "\n",
    "for version in latest_versions:\n",
    "    print(f\"version: {version.version}, stage: {version.current_stage}\")\n",
    "    model_ver = version.version\n",
    "print(model_ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1681116727851, current_stage='Staging', description=None, last_updated_timestamp=1681117231554, name='laptop-price-demo', run_id='128731dce22e4a06bed20def94cf81db', run_link=None, source='./mlruns/2/128731dce22e4a06bed20def94cf81db/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 1\n",
    "new_stage = \"Staging\"\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    stage=new_stage,\n",
    "    archive_existing_versions=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1681116727851, current_stage='Staging', description='The model version 1 was transitioned to Staging on 2023-04-10', last_updated_timestamp=1681117281118, name='laptop-price-demo', run_id='128731dce22e4a06bed20def94cf81db', run_link=None, source='./mlruns/2/128731dce22e4a06bed20def94cf81db/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date = datetime.today().date()\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    description=f\"The model version {model_version} was transitioned to {new_stage} on {date}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME=\"laptop-price-demoV1\"\n",
    "HYPERPARAMETER_TUNING_EXPERIMENT = \"hyper-optimization-experiment-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_model(MLFLOW_TRACKING_URI, MODEL_NAME):\n",
    "    \"\"\" this function is responsible for taking the model in tuning experiment to model registry\n",
    "    MLFLOW_TRACKING_URI : is the sqlite database used by the tracking server to track the experiments\n",
    "    \"\"\"\n",
    "    # interacting with the mlflow beckend tracker\\ tracking server\n",
    "    client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "    # client.get_experiment(experiment_id=2)\n",
    "\n",
    "    best_run = client.search_runs(\n",
    "    experiment_ids='2',\n",
    "    filter_string=\"metrics.rmse < 7\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=2,\n",
    "    order_by=[\"metrics.rmse ASC\"])[1]\n",
    "\n",
    "    # interacting with model registry\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    \n",
    "    model_uri = f\"runs:/{best_run.info.run_id}/model\"\n",
    "    mlflow.register_model(model_uri=model_uri, name=MODEL_NAME)\n",
    "    \n",
    "    latest_versions = client.get_latest_versions(name=MODEL_NAME)\n",
    "    for version in latest_versions:\n",
    "        model_version = version.version\n",
    "        \n",
    "    # registering the fresh new model into staging\n",
    "    new_stage = \"Staging\"\n",
    "    client.transition_model_version_stage(\n",
    "        name=MODEL_NAME,\n",
    "        version=model_version,\n",
    "        stage=new_stage,\n",
    "        archive_existing_versions=False\n",
    "    )\n",
    "    \n",
    "    # update the mlflow client\n",
    "    date = datetime.today().date()\n",
    "    client.update_model_version(\n",
    "        name=MODEL_NAME,\n",
    "        version=model_version,\n",
    "        description=f\"The model version {model_version} was transitioned to {new_stage} on {date}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'laptop-price-demoV1' already exists. Creating a new version of this model...\n",
      "2023/04/10 13:04:28 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: laptop-price-demoV1, version 2\n",
      "Created version '2' of model 'laptop-price-demoV1'.\n"
     ]
    }
   ],
   "source": [
    "register_model(MLFLOW_TRACKING_URI,MODEL_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing model versions and selecting the best for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation_data():\n",
    "    \"\"\" it gets the evalutiion data that has not been touched or tempered from the dataset repo and\n",
    "    uses it to evaluate the staging model against the production model(IF the production model is present), if not the \n",
    "    staging model automatically moves to  productionn label and and gets deployed.\n",
    "    NB: In case where the two models are compared(Prod vs Staging), the better model is deployed and the currently in prod\n",
    "    moddel gets removed to archivedd models.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
